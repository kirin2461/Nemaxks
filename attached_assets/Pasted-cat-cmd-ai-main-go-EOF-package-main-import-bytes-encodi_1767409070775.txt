cat > cmd/ai/main.go << 'EOF'
package main

import (
    "bytes"
    "encoding/json"
    "fmt"
    "io"
    "log"
    "net/http"
    "os"
    "github.com/gin-contrib/cors"
    "github.com/gin-gonic/gin"
    "github.com/joho/godotenv"
)

const OLLAMA_URL = "http://localhost:11434/api/generate"

type OllamaRequest struct {
    Model  string `json:"model"`
    Prompt string `json:"prompt"`
    Stream bool   `json:"stream"`
}

type OllamaResponse struct {
    Response string `json:"response"`
    Done     bool   `json:"done"`
}

type JarvisRequest struct {
    Message   string `json:"message" binding:"required"`
    Context   string `json:"context,omitempty"`
    UserId    string `json:"user_id,omitempty"`
    ChannelId string `json:"channel_id,omitempty"`
}

type JarvisResponse struct {
    Response string `json:"response"`
    Actions  string `json:"actions,omitempty"`
}

func main() {
    godotenv.Load()

    r := gin.Default()

    config := cors.DefaultConfig()
    config.AllowAllOrigins = true
    config.AllowCredentials = true
    r.Use(cors.New(config))

    // Health check
    r.GET("/health", func(c *gin.Context) {
        c.JSON(http.StatusOK, gin.H{
            "message":   "Jarvis AI Service",
            "status":    "running",
            "ollama": "connected",
        })
    })

    // Chat with Jarvis
    r.POST("/chat", handleJarvisChat)

    // Execute command
    r.POST("/command", handleJarvisCommand)

    port := getEnv("AI_PORT", "5003")
    log.Printf("Jarvis AI Service running on port %s", port)
    log.Printf("Using Ollama at %s", OLLAMA_URL)
    r.Run("0.0.0.0:" + port)
}

func handleJarvisChat(c *gin.Context) {
    var req JarvisRequest
    if err := c.BindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request"})
        return
    }

    systemPrompt := `You are Jarvis, an advanced AI assistant for the Nemaks communication platform. You help users with:
- Managing servers and channels
- Answering questions
- Executing commands
- Moderating content
- Providing information

Be helpful, concise, and professional. If asked to perform an action, respond with JSON containing actions array.`

    fullPrompt := fmt.Sprintf("%s\n\n%s", systemPrompt, req.Message)

    ollamaReq := OllamaRequest{
        Model:  "llama2",
        Prompt: fullPrompt,
        Stream: false,
    }

    response, err := callOllama(ollamaReq)
    if err != nil {
        log.Printf("Ollama error: %v", err)
        c.JSON(http.StatusInternalServerError, gin.H{"error": "AI service unavailable"})
        return
    }

    c.JSON(http.StatusOK, JarvisResponse{
        Response: response,
        Actions:  "",
    })
}

func handleJarvisCommand(c *gin.Context) {
    var req struct {
        Command string `json:"command" binding:"required"`
        Args    string `json:"args,omitempty"`
    }

    if err := c.BindJSON(&req); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
        return
    }

    switch req.Command {
    case "create_channel":
        c.JSON(http.StatusOK, gin.H{
            "success": true,
            "message": "Channel created by Jarvis",
        })
    case "moderate":
        c.JSON(http.StatusOK, gin.H{
            "success": true,
            "message": "Content moderated",
        })
    default:
        c.JSON(http.StatusOK, gin.H{
            "success": false,
            "message": "Unknown command",
        })
    }
}

func callOllama(req OllamaRequest) (string, error) {
    jsonData, _ := json.Marshal(req)
    resp, err := http.Post(OLLAMA_URL, "application/json", bytes.NewBuffer(jsonData))
    if err != nil {
        return "", err
    }
    defer resp.Body.Close()

    body, _ := io.ReadAll(resp.Body)
    var ollamaResp OllamaResponse
    if err := json.Unmarshal(body, &ollamaResp); err != nil {
        return "", err
    }

    return ollamaResp.Response, nil
}

func getEnv(key, fallback string) string {
    if value := os.Getenv(key); value != "" {
        return value
    }
    return fallback
}
EOF